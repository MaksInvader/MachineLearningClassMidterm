{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d80ffe",
   "metadata": {},
   "source": [
    "# ðŸ’³ Fraud Detection - Model Training\n",
    "\n",
    "This notebook trains multiple machine learning models for fraud detection using the preprocessed transaction data.\n",
    "\n",
    "**Models Trained:**\n",
    "1. **Logistic Regression** - Baseline linear model\n",
    "2. **Decision Tree** - Interpretable tree-based model  \n",
    "3. **Random Forest** - Ensemble of decision trees\n",
    "4. **XGBoost** - Gradient boosting (best for imbalanced data)\n",
    "5. **LightGBM** - Fast gradient boosting\n",
    "6. **Gradient Boosting** - Scikit-learn ensemble method\n",
    "\n",
    "**Data Source:** `train_transaction_processed.csv` (feature-engineered dataset from EDA)\n",
    "\n",
    "**Class Imbalance Handling:**\n",
    "- SMOTE (Synthetic Minority Over-sampling) with 0.3 ratio\n",
    "- Class weights balancing\n",
    "- Stratified train-validation split\n",
    "\n",
    "**Output:** Trained models saved as PKL files for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94417b",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43817b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All libraries imported successfully\n",
      "âœ“ XGBoost available\n",
      "âœ“ LightGBM available\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Try to import XGBoost and LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgboost_available = True\n",
    "except ImportError:\n",
    "    xgboost_available = False\n",
    "    print(\"âš  XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    lightgbm_available = True\n",
    "except ImportError:\n",
    "    lightgbm_available = False\n",
    "    print(\"âš  LightGBM not available. Install with: pip install lightgbm\")\n",
    "\n",
    "# Imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Metrics for quick evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")\n",
    "if xgboost_available:\n",
    "    print(\"âœ“ XGBoost available\")\n",
    "if lightgbm_available:\n",
    "    print(\"âœ“ LightGBM available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b622767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data from EDA...\n",
      "\n",
      "âœ“ Data loaded: (590540, 429)\n",
      "Columns: 429\n",
      "Rows: 590,540\n",
      "\n",
      "Note: Using train_transaction_processed.csv with engineered features\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data from EDA notebook\n",
    "print(\"Loading preprocessed data from EDA...\\n\")\n",
    "\n",
    "# Load the processed dataset with feature engineering\n",
    "train_data = pd.read_csv('train_transaction_processed.csv')\n",
    "\n",
    "print(f\"âœ“ Data loaded: {train_data.shape}\")\n",
    "print(f\"Columns: {train_data.shape[1]}\")\n",
    "print(f\"Rows: {train_data.shape[0]:,}\")\n",
    "print(f\"\\nNote: Using train_transaction_processed.csv with engineered features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81b6a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Dataset Overview:\n",
      "   Features: 411\n",
      "   Samples: 590,540\n",
      "\n",
      "ðŸŽ¯ Target Distribution:\n",
      "   Not Fraud: 569,877 (96.50%)\n",
      "   Fraud: 20,663 (3.50%)\n",
      "   Imbalance Ratio: 1:27\n",
      "\n",
      "ðŸ“‚ Creating stratified train-validation split (80-20)...\n",
      "âœ“ Train set: 472,432 samples\n",
      "âœ“ Validation set: 118,108 samples\n",
      "\n",
      "Train fraud rate: 3.50%\n",
      "Validation fraud rate: 3.50%\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "if 'isFraud' in train_data.columns:\n",
    "    X = train_data.drop(columns=['isFraud'])\n",
    "    y = train_data['isFraud']\n",
    "else:\n",
    "    raise ValueError(\"Target variable 'isFraud' not found in dataset\")\n",
    "\n",
    "# Remove ID columns if present\n",
    "id_cols = ['TransactionID', 'TransactionDT']\n",
    "X = X.drop(columns=[col for col in id_cols if col in X.columns], errors='ignore')\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Select only numeric columns for training\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "print(f\"   Samples: {X.shape[0]:,}\")\n",
    "print(f\"\\nðŸŽ¯ Target Distribution:\")\n",
    "print(f\"   Not Fraud: {(y == 0).sum():,} ({(y == 0).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"   Fraud: {(y == 1).sum():,} ({(y == 1).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"   Imbalance Ratio: 1:{(y == 0).sum() // (y == 1).sum()}\")\n",
    "\n",
    "# Stratified train-validation split (80-20)\n",
    "print(f\"\\nðŸ“‚ Creating stratified train-validation split (80-20)...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain fraud ratio\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Train set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"âœ“ Validation set: {X_val.shape[0]:,} samples\")\n",
    "print(f\"\\nTrain fraud rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Validation fraud rate: {y_val.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e83684",
   "metadata": {},
   "source": [
    "## 2. Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a5547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "APPLYING SMOTE TO BALANCE CLASSES\n",
      "================================================================================\n",
      "\n",
      "Before SMOTE:\n",
      "Training samples: 472,432\n",
      "Fraud cases: 16,530 (3.50%)\n",
      "Not Fraud cases: 455,902 (96.50%)\n",
      "\n",
      "After SMOTE:\n",
      "Training samples: 592,672\n",
      "Fraud cases: 136,770 (23.08%)\n",
      "Not Fraud cases: 455,902 (76.92%)\n",
      "\n",
      "âœ“ SMOTE applied successfully\n",
      "Note: Using 0.3 ratio for better generalization on highly imbalanced data\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"{'='*80}\")\n",
    "print(\"APPLYING SMOTE TO BALANCE CLASSES\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"Before SMOTE:\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Fraud cases: {y_train.sum():,} ({(y_train.sum()/len(y_train))*100:.2f}%)\")\n",
    "print(f\"Not Fraud cases: {(y_train == 0).sum():,} ({((y_train == 0).sum()/len(y_train))*100:.2f}%)\")\n",
    "\n",
    "# Apply SMOTE with optimal sampling strategy for fraud detection\n",
    "# Using 0.3 ratio - fraud becomes 30% of majority (better than 50% for high imbalance)\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.3, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(f\"Training samples: {len(X_train_smote):,}\")\n",
    "print(f\"Fraud cases: {y_train_smote.sum():,} ({(y_train_smote.sum()/len(y_train_smote))*100:.2f}%)\")\n",
    "print(f\"Not Fraud cases: {(y_train_smote == 0).sum():,} ({((y_train_smote == 0).sum()/len(y_train_smote))*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nâœ“ SMOTE applied successfully\")\n",
    "print(\"Note: Using 0.3 ratio for better generalization on highly imbalanced data\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before SMOTE\n",
    "axes[0].bar(['Not Fraud', 'Fraud'], [(y_train == 0).sum(), y_train.sum()], \n",
    "            color=['green', 'red'], edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Before SMOTE', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate([(y_train == 0).sum(), y_train.sum()]):\n",
    "    axes[0].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# After SMOTE\n",
    "axes[1].bar(['Not Fraud', 'Fraud'], [(y_train_smote == 0).sum(), y_train_smote.sum()], \n",
    "            color=['green', 'red'], edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('After SMOTE (30% Ratio)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate([(y_train_smote == 0).sum(), y_train_smote.sum()]):\n",
    "    axes[1].text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a73ad",
   "metadata": {},
   "source": [
    "## 3. Model Training Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9243013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_model(model, model_name, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train a model and return comprehensive evaluation metrics including confusion matrix\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING: {model_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ“ Model trained in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Get probability scores if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_pred_proba = model.decision_function(X_val)\n",
    "    else:\n",
    "        y_pred_proba = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Validation Results:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f} (of predicted frauds, how many are correct)\")\n",
    "    print(f\"   Recall:    {recall:.4f} (of actual frauds, how many we caught)\")\n",
    "    print(f\"   F1-Score:  {f1:.4f} (harmonic mean of precision & recall)\")\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "            print(f\"   ROC-AUC:   {roc_auc:.4f}\")\n",
    "        except:\n",
    "            roc_auc = None\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Confusion Matrix:\")\n",
    "    print(f\"   TN: {cm[0,0]:6,}  |  FP: {cm[0,1]:6,}\")\n",
    "    print(f\"   FN: {cm[1,0]:6,}  |  TP: {cm[1,1]:6,}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'training_time': training_time,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94a6fe",
   "metadata": {},
   "source": [
    "## 4. Model 1: Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419aa512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: Logistic Regression\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 253.79 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.7809\n",
      "   Precision: 0.1024 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.6780 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.1780 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.7945\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 89,426  |  FP: 24,549\n",
      "   FN:  1,331  |  TP:  2,802\n",
      "\n",
      "âœ“ Model saved: model_logistic_regression.pkl\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - Good baseline for binary classification\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',  # Handle imbalance\n",
    "    solver='lbfgs',  # Good for large datasets\n",
    "    C=1.0  # Regularization strength\n",
    ")\n",
    "\n",
    "lr_results = train_and_evaluate_model(\n",
    "    lr_model, \"Logistic Regression\",\n",
    "    X_train_smote, y_train_smote, X_val, y_val\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "print(\"\\nâœ“ Model saved: model_logistic_regression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0c983",
   "metadata": {},
   "source": [
    "## 5. Model 2: Decision Tree (Interpretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44253fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: Decision Tree\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 64.96 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9378\n",
      "   Precision: 0.2997 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5812 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.3955 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.8519\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 108,362  |  FP:  5,613\n",
      "   FN:  1,731  |  TP:  2,402\n",
      "\n",
      "Tree Statistics:\n",
      "   Tree depth: 15\n",
      "   Number of leaves: 1624\n",
      "\n",
      "âœ“ Model saved: model_decision_tree.pkl\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Interpretable model with pruning to prevent overfitting\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=15,  # Increased from 10 for better performance\n",
    "    min_samples_split=50,  # Reduced for more splits\n",
    "    min_samples_leaf=25,  # Minimum samples per leaf\n",
    "    class_weight='balanced',\n",
    "    criterion='gini'  # or 'entropy'\n",
    ")\n",
    "\n",
    "dt_results = train_and_evaluate_model(\n",
    "    dt_model, \"Decision Tree\",\n",
    "    X_train_smote, y_train_smote, X_val, y_val\n",
    ")\n",
    "\n",
    "print(f\"\\nTree Statistics:\")\n",
    "print(f\"   Tree depth: {dt_model.get_depth()}\")\n",
    "print(f\"   Number of leaves: {dt_model.get_n_leaves()}\")\n",
    "\n",
    "# Save model\n",
    "with open('model_decision_tree.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "print(\"\\nâœ“ Model saved: model_decision_tree.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98926f9e",
   "metadata": {},
   "source": [
    "## 6. Model 3: Random Forest (Ensemble - Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b5633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: Random Forest\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 200.18 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9740\n",
      "   Precision: 0.6471 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5669 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.6043 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9201\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 112,697  |  FP:  1,278\n",
      "   FN:  1,790  |  TP:  2,343\n",
      "\n",
      "Model Statistics:\n",
      "   Number of trees: 200\n",
      "   Max features per split: sqrt(411) = 20\n",
      "\n",
      "âœ“ Model saved: model_random_forest.pkl\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Best balance of performance and interpretability\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,  # More trees for better performance\n",
    "    random_state=42,\n",
    "    max_depth=20,  # Deeper trees\n",
    "    min_samples_split=20,  # More aggressive splitting\n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',  # Good default for classification\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    bootstrap=True\n",
    ")\n",
    "\n",
    "rf_results = train_and_evaluate_model(\n",
    "    rf_model, \"Random Forest\",\n",
    "    X_train_smote, y_train_smote, X_val, y_val\n",
    ")\n",
    "\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"   Number of trees: {rf_model.n_estimators}\")\n",
    "print(f\"   Max features per split: sqrt({X_train.shape[1]}) = {int(np.sqrt(X_train.shape[1]))}\")\n",
    "\n",
    "# Save model\n",
    "with open('model_random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(\"\\nâœ“ Model saved: model_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a88e8",
   "metadata": {},
   "source": [
    "## 7. Model 4: XGBoost (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe50e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: XGBoost\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 76.81 seconds\n",
      "âœ“ Model trained in 76.81 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9830\n",
      "   Precision: 0.8164 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.6627 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.7316 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9624\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 113,359  |  FP:    616\n",
      "   FN:  1,394  |  TP:  2,739\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting rounds: 200\n",
      "   Scale pos weight: 3.33\n",
      "\n",
      "âœ“ Model saved: model_xgboost.json\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9830\n",
      "   Precision: 0.8164 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.6627 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.7316 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9624\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 113,359  |  FP:    616\n",
      "   FN:  1,394  |  TP:  2,739\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting rounds: 200\n",
      "   Scale pos weight: 3.33\n",
      "\n",
      "âœ“ Model saved: model_xgboost.json\n"
     ]
    }
   ],
   "source": [
    "if xgboost_available:\n",
    "    # XGBoost - Excellent for imbalanced classification\n",
    "    # Calculate scale_pos_weight for imbalance\n",
    "    scale_pos_weight = (y_train_smote == 0).sum() / (y_train_smote == 1).sum()\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,  # Row sampling\n",
    "        colsample_bytree=0.8,  # Column sampling\n",
    "        gamma=0,  # Minimum loss reduction\n",
    "        min_child_weight=3,\n",
    "        scale_pos_weight=scale_pos_weight,  # Handle imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    xgb_results = train_and_evaluate_model(\n",
    "        xgb_model, \"XGBoost\",\n",
    "        X_train_smote, y_train_smote, X_val, y_val\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel Statistics:\")\n",
    "    print(f\"   Number of boosting rounds: {xgb_model.n_estimators}\")\n",
    "    print(f\"   Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "    \n",
    "    # Save model\n",
    "    xgb_model.save_model('model_xgboost.json')\n",
    "    print(\"\\nâœ“ Model saved: model_xgboost.json\")\n",
    "else:\n",
    "    print(\"âš  XGBoost not available. Skipping...\")\n",
    "    xgb_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c505b8",
   "metadata": {},
   "source": [
    "## 8. Model 5: LightGBM (Fast Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940c4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: LightGBM\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 34.55 seconds\n",
      "âœ“ Model trained in 34.55 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9750\n",
      "   Precision: 0.6616 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5846 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.6207 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9340\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 112,739  |  FP:  1,236\n",
      "   FN:  1,717  |  TP:  2,416\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting rounds: 200\n",
      "   Number of leaves: 31\n",
      "\n",
      "âœ“ Model saved: model_lightgbm.pkl\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9750\n",
      "   Precision: 0.6616 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5846 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.6207 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9340\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 112,739  |  FP:  1,236\n",
      "   FN:  1,717  |  TP:  2,416\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting rounds: 200\n",
      "   Number of leaves: 31\n",
      "\n",
      "âœ“ Model saved: model_lightgbm.pkl\n"
     ]
    }
   ],
   "source": [
    "if lightgbm_available:\n",
    "    # LightGBM - Fast and efficient gradient boosting\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,  # Should be < 2^max_depth\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        min_child_samples=20,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgb_results = train_and_evaluate_model(\n",
    "        lgb_model, \"LightGBM\",\n",
    "        X_train_smote, y_train_smote, X_val, y_val\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel Statistics:\")\n",
    "    print(f\"   Number of boosting rounds: {lgb_model.n_estimators}\")\n",
    "    print(f\"   Number of leaves: {lgb_model.num_leaves}\")\n",
    "    \n",
    "    # Save model\n",
    "    with open('model_lightgbm.pkl', 'wb') as f:\n",
    "        pickle.dump(lgb_model, f)\n",
    "    print(\"\\nâœ“ Model saved: model_lightgbm.pkl\")\n",
    "else:\n",
    "    print(\"âš  LightGBM not available. Skipping...\")\n",
    "    lgb_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fab3af",
   "metadata": {},
   "source": [
    "## 9. Model 6: Gradient Boosting (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70223c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING: Gradient Boosting\n",
      "================================================================================\n",
      "\n",
      "âœ“ Model trained in 602.36 seconds\n",
      "âœ“ Model trained in 602.36 seconds\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9818\n",
      "   Precision: 0.9073 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5352 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.6733 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9477\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 113,749  |  FP:    226\n",
      "   FN:  1,921  |  TP:  2,212\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting stages: 200\n",
      "   Effective estimators used: 200\n",
      "\n",
      "âœ“ Model saved: model_gradient_boosting.pkl\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "   Accuracy:  0.9818\n",
      "   Precision: 0.9073 (of predicted frauds, how many are correct)\n",
      "   Recall:    0.5352 (of actual frauds, how many we caught)\n",
      "   F1-Score:  0.6733 (harmonic mean of precision & recall)\n",
      "   ROC-AUC:   0.9477\n",
      "\n",
      "ðŸ“ˆ Confusion Matrix:\n",
      "   TN: 113,749  |  FP:    226\n",
      "   FN:  1,921  |  TP:  2,212\n",
      "\n",
      "Model Statistics:\n",
      "   Number of boosting stages: 200\n",
      "   Effective estimators used: 200\n",
      "\n",
      "âœ“ Model saved: model_gradient_boosting.pkl\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting - Powerful ensemble method\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,  # Stochastic gradient boosting\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    validation_fraction=0.1,  # For early stopping monitoring\n",
    "    n_iter_no_change=10  # Early stopping\n",
    ")\n",
    "\n",
    "gb_results = train_and_evaluate_model(\n",
    "    gb_model, \"Gradient Boosting\",\n",
    "    X_train_smote, y_train_smote, X_val, y_val\n",
    ")\n",
    "\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"   Number of boosting stages: {gb_model.n_estimators}\")\n",
    "print(f\"   Effective estimators used: {gb_model.n_estimators_}\")\n",
    "\n",
    "# Save model\n",
    "with open('model_gradient_boosting.pkl', 'wb') as f:\n",
    "    pickle.dump(gb_model, f)\n",
    "print(\"\\nâœ“ Model saved: model_gradient_boosting.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec6bab",
   "metadata": {},
   "source": [
    "## 10. Compile and Save All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6484ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING SUMMARY - ALL MODELS\n",
      "================================================================================\n",
      "\n",
      "              Model  Training Time (s)  Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "Logistic Regression         253.787112  0.780879   0.102446 0.677958  0.177995 0.794543\n",
      "      Decision Tree          64.960482  0.937820   0.299688 0.581176  0.395456 0.851948\n",
      "      Random Forest         200.179184  0.974024   0.647059 0.566901  0.604333 0.920100\n",
      "            XGBoost          76.806084  0.982982   0.816393 0.662715  0.731571 0.962368\n",
      "           LightGBM          34.552045  0.974997   0.661555 0.584563  0.620681 0.934037\n",
      "  Gradient Boosting         602.361072  0.981822   0.907301 0.535204  0.673261 0.947717\n",
      "\n",
      "âœ“ Training summary saved: training_results_summary.csv\n",
      "âœ“ All model results saved: all_model_results.pkl\n",
      "âœ“ All model results saved: all_model_results.pkl\n",
      "âœ“ Train/val split saved: train_val_split.pkl\n",
      "âœ“ Train/val split saved: train_val_split.pkl\n"
     ]
    }
   ],
   "source": [
    "# Compile all results\n",
    "all_results = [lr_results, dt_results, rf_results]\n",
    "\n",
    "if xgboost_available and xgb_results:\n",
    "    all_results.append(xgb_results)\n",
    "\n",
    "if lightgbm_available and lgb_results:\n",
    "    all_results.append(lgb_results)\n",
    "\n",
    "all_results.append(gb_results)\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_summary = pd.DataFrame([{\n",
    "    'Model': r['model_name'],\n",
    "    'Training Time (s)': r['training_time'],\n",
    "    'Accuracy': r['accuracy'],\n",
    "    'Precision': r['precision'],\n",
    "    'Recall': r['recall'],\n",
    "    'F1-Score': r['f1'],\n",
    "    'ROC-AUC': r['roc_auc'] if r['roc_auc'] else 'N/A'\n",
    "} for r in all_results])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING SUMMARY - ALL MODELS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(results_summary.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_summary.to_csv('training_results_summary.csv', index=False)\n",
    "print(f\"\\nâœ“ Training summary saved: training_results_summary.csv\")\n",
    "\n",
    "# Save all results for evaluation notebook\n",
    "with open('all_model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "print(f\"âœ“ All model results saved: all_model_results.pkl\")\n",
    "\n",
    "# Save train/val split for evaluation\n",
    "with open('train_val_split.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'X_val': X_val,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'X_train_smote': X_train_smote,\n",
    "        'y_train_smote': y_train_smote\n",
    "    }, f)\n",
    "print(f\"âœ“ Train/val split saved: train_val_split.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e946d4a",
   "metadata": {},
   "source": [
    "## 11. Training Complete - Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab843358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… MODEL TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Trained 6 models:\n",
      "   1. Logistic Regression\n",
      "      â€¢ F1-Score: 0.1780\n",
      "      â€¢ Recall: 0.6780\n",
      "      â€¢ Training Time: 253.79s\n",
      "   2. Decision Tree\n",
      "      â€¢ F1-Score: 0.3955\n",
      "      â€¢ Recall: 0.5812\n",
      "      â€¢ Training Time: 64.96s\n",
      "   3. Random Forest\n",
      "      â€¢ F1-Score: 0.6043\n",
      "      â€¢ Recall: 0.5669\n",
      "      â€¢ Training Time: 200.18s\n",
      "   4. XGBoost\n",
      "      â€¢ F1-Score: 0.7316\n",
      "      â€¢ Recall: 0.6627\n",
      "      â€¢ Training Time: 76.81s\n",
      "   5. LightGBM\n",
      "      â€¢ F1-Score: 0.6207\n",
      "      â€¢ Recall: 0.5846\n",
      "      â€¢ Training Time: 34.55s\n",
      "   6. Gradient Boosting\n",
      "      â€¢ F1-Score: 0.6733\n",
      "      â€¢ Recall: 0.5352\n",
      "      â€¢ Training Time: 602.36s\n",
      "\n",
      "ðŸ† Best Model (by F1-Score): XGBoost\n",
      "   F1-Score: 0.7316\n",
      "\n",
      "ðŸ“ Generated Files:\n",
      "   Models:\n",
      "   â€¢ model_logistic_regression.pkl\n",
      "   â€¢ model_decision_tree.pkl\n",
      "   â€¢ model_random_forest.pkl\n",
      "   â€¢ model_xgboost.json\n",
      "   â€¢ model_lightgbm.pkl\n",
      "   â€¢ model_gradient_boosting.pkl\n",
      "\n",
      "   Results:\n",
      "   â€¢ training_results_summary.csv\n",
      "   â€¢ all_model_results.pkl\n",
      "   â€¢ train_val_split.pkl\n",
      "\n",
      "ðŸ’¡ Next Steps:\n",
      "   1. Open Model_Evaluation.ipynb for detailed model comparison\n",
      "   2. Analyze confusion matrices, ROC curves, and feature importance\n",
      "   3. Select the best model based on business requirements\n",
      "   4. Apply the best model to test_transaction.csv\n",
      "\n",
      "================================================================================\n",
      "Proceed to Model_Evaluation.ipynb for comprehensive evaluation!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"âœ… MODEL TRAINING COMPLETE!\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"ðŸ“Š Trained {len(all_results)} models:\")\n",
    "for i, r in enumerate(all_results, 1):\n",
    "    print(f\"   {i}. {r['model_name']}\")\n",
    "    print(f\"      â€¢ F1-Score: {r['f1']:.4f}\")\n",
    "    print(f\"      â€¢ Recall: {r['recall']:.4f}\")\n",
    "    print(f\"      â€¢ Training Time: {r['training_time']:.2f}s\")\n",
    "\n",
    "# Find best model by F1-score\n",
    "best_model = max(all_results, key=lambda x: x['f1'])\n",
    "print(f\"\\nðŸ† Best Model (by F1-Score): {best_model['model_name']}\")\n",
    "print(f\"   F1-Score: {best_model['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Generated Files:\")\n",
    "print(f\"   Models:\")\n",
    "print(f\"   â€¢ model_logistic_regression.pkl\")\n",
    "print(f\"   â€¢ model_decision_tree.pkl\")\n",
    "print(f\"   â€¢ model_random_forest.pkl\")\n",
    "if xgboost_available:\n",
    "    print(f\"   â€¢ model_xgboost.json\")\n",
    "if lightgbm_available:\n",
    "    print(f\"   â€¢ model_lightgbm.pkl\")\n",
    "print(f\"   â€¢ model_gradient_boosting.pkl\")\n",
    "\n",
    "print(f\"\\n   Results:\")\n",
    "print(f\"   â€¢ training_results_summary.csv\")\n",
    "print(f\"   â€¢ all_model_results.pkl\")\n",
    "print(f\"   â€¢ train_val_split.pkl\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Next Steps:\")\n",
    "print(f\"   1. Open Model_Evaluation.ipynb for detailed model comparison\")\n",
    "print(f\"   2. Analyze confusion matrices, ROC curves, and feature importance\")\n",
    "print(f\"   3. Select the best model based on business requirements\")\n",
    "print(f\"   4. Apply the best model to test_transaction.csv\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Proceed to Model_Evaluation.ipynb for comprehensive evaluation!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_env)",
   "language": "python",
   "name": "conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
