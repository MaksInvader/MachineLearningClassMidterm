{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c9581a",
   "metadata": {},
   "source": [
    "# üöÄ GPU-Accelerated Song Release Year Prediction - Model Training (RAPIDS)\n",
    "\n",
    "This notebook trains multiple regression models using **RAPIDS cuML** for GPU acceleration where available, with CPU fallback for unsupported models.\n",
    "\n",
    "**Dataset Context:** Audio features of songs (timbre, pitch, rhythm, etc.) used to predict release year.\n",
    "\n",
    "**RAPIDS cuML Benefits:**\n",
    "- üî• 10-100x faster model training on GPU\n",
    "- ‚ö° Same API as scikit-learn\n",
    "- \udd04 Automatic CPU fallback for unsupported models\n",
    "\n",
    "## Models to Train:\n",
    "1. **Linear Regression** (cuML GPU or sklearn CPU)\n",
    "2. **Ridge Regression** (cuML GPU or sklearn CPU)\n",
    "3. **Lasso Regression** (cuML GPU or sklearn CPU)\n",
    "4. **ElasticNet Regression** (cuML GPU or sklearn CPU)\n",
    "5. **Decision Tree Regressor** (sklearn CPU - no GPU version)\n",
    "6. **Random Forest Regressor** (cuML GPU or sklearn CPU)\n",
    "7. **Gradient Boosting Regressor** (sklearn CPU - no GPU version)\n",
    "8. **XGBoost Regressor** (GPU hist or CPU - if available)\n",
    "9. **Support Vector Regressor** (sklearn CPU - no GPU version)\n",
    "10. **K-Nearest Neighbors Regressor** (cuML GPU or sklearn CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Check GPU availability and import RAPIDS\n",
    "print(\"=\"*80)\n",
    "print(\"GPU AVAILABILITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import cudf\n",
    "    from cuml.model_selection import train_test_split as cu_train_test_split\n",
    "    from cuml.linear_model import LinearRegression as cuLinearRegression\n",
    "    from cuml.linear_model import Ridge as cuRidge\n",
    "    from cuml.linear_model import Lasso as cuLasso\n",
    "    from cuml.linear_model import ElasticNet as cuElasticNet\n",
    "    from cuml.ensemble import RandomForestRegressor as cuRandomForestRegressor\n",
    "    from cuml.neighbors import KNeighborsRegressor as cuKNeighborsRegressor\n",
    "    from cuml.metrics import mean_squared_error as cu_mse\n",
    "    from cuml.metrics import r2_score as cu_r2_score\n",
    "    \n",
    "    rapids_available = True\n",
    "    print(\"‚úì RAPIDS cuML available\")\n",
    "    gpu_count = cp.cuda.runtime.getDeviceCount()\n",
    "    print(f\"‚úì GPUs available: {gpu_count}\")\n",
    "    \n",
    "    if gpu_count > 0:\n",
    "        gpu_name = cp.cuda.runtime.getDeviceProperties(0)['name'].decode()\n",
    "        gpu_mem = cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem'] / 1e9\n",
    "        print(f\"‚úì GPU 0: {gpu_name}\")\n",
    "        print(f\"‚úì GPU Memory: {gpu_mem:.1f} GB\")\n",
    "        \n",
    "except ImportError:\n",
    "    rapids_available = False\n",
    "    print(\"‚ùå RAPIDS not available\")\n",
    "    print(\"\\nüì¶ Installation: conda install -c rapidsai -c conda-forge -c nvidia rapids\")\n",
    "    print(\"\\nFalling back to CPU training with scikit-learn...\")\n",
    "\n",
    "# Standard sklearn imports (for CPU fallback and non-GPU models)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Try to import XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgboost_available = True\n",
    "    print(\"‚úì XGBoost available\")\n",
    "except ImportError:\n",
    "    xgboost_available = False\n",
    "    print(\"‚ö† XGBoost not available\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"\\n‚úì All libraries imported successfully!\")\n",
    "print(f\"üöÄ GPU Acceleration: {'ENABLED' if rapids_available else 'DISABLED (CPU mode)'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346b386",
   "metadata": {},
   "source": [
    "## Load Processed Song Features Data (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed and scaled data directly to GPU\n",
    "print(\"Loading processed song features data to GPU...\\n\")\n",
    "\n",
    "# Load data with cuDF (directly to GPU)\n",
    "gdf = cudf.read_csv('cars_scaled_standard_rapids.csv')\n",
    "\n",
    "print(f\"‚úì Data loaded to GPU: {gdf.shape}\")\n",
    "print(f\"Columns (audio features): {gdf.shape[1]}\")\n",
    "print(f\"Rows (songs): {gdf.shape[0]:,}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows:\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165b0b7",
   "metadata": {},
   "source": [
    "## Prepare Features and Target (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81becc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_col = gdf.columns[0]\n",
    "X = gdf.drop(columns=[target_col])\n",
    "y = gdf[target_col]\n",
    "\n",
    "print(f\"Target variable: {target_col} (Song Release Year)\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]:,}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9520f",
   "metadata": {},
   "source": [
    "## Train-Test Split (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e933e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data using cuML (on GPU)\n",
    "print(\"Splitting data into train and test sets on GPU...\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = cu_train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} songs\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} songs\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Save test indices for later evaluation\n",
    "test_indices = X_test.index.to_pandas()\n",
    "with open('test_indices_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(test_indices, f)\n",
    "print(\"\\n‚úì Test indices saved for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34905735",
   "metadata": {},
   "source": [
    "## Define Model Evaluation Functions (CPU & GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate a sklearn model on CPU\n",
    "    Returns: dictionary with model performance metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Training Results:\")\n",
    "    print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"\\n   Training Set:\")\n",
    "    print(f\"   - RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"   - MAE:  {train_mae:.4f}\")\n",
    "    print(f\"   - R¬≤:   {train_r2:.4f}\")\n",
    "    print(f\"\\n   Test Set:\")\n",
    "    print(f\"   - RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"   - MAE:  {test_mae:.4f}\")\n",
    "    print(f\"   - R¬≤:   {test_r2:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    if train_r2 - test_r2 > 0.1:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Possible overfitting detected (R¬≤ difference: {train_r2 - test_r2:.4f})\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'training_time': training_time,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred\n",
    "    }\n",
    "\n",
    "print(\"‚úì CPU evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_gpu(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate a cuML model on GPU\n",
    "    Returns: dictionary with model performance metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions (on GPU)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics (some on GPU, some on CPU)\n",
    "    # cuML metrics (GPU)\n",
    "    train_rmse = cp.sqrt(cu_mse(y_train, y_train_pred))\n",
    "    test_rmse = cp.sqrt(cu_mse(y_test, y_test_pred))\n",
    "    train_r2 = cu_r2_score(y_train, y_train_pred)\n",
    "    test_r2 = cu_r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # MAE not in cuML yet, use numpy (transfer to CPU)\n",
    "    train_mae = mean_absolute_error(\n",
    "        y_train.to_numpy() if hasattr(y_train, 'to_numpy') else cp.asnumpy(y_train),\n",
    "        y_train_pred.to_numpy() if hasattr(y_train_pred, 'to_numpy') else cp.asnumpy(y_train_pred)\n",
    "    )\n",
    "    test_mae = mean_absolute_error(\n",
    "        y_test.to_numpy() if hasattr(y_test, 'to_numpy') else cp.asnumpy(y_test),\n",
    "        y_test_pred.to_numpy() if hasattr(y_test_pred, 'to_numpy') else cp.asnumpy(y_test_pred)\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Training Results:\")\n",
    "    print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"\\n   Training Set:\")\n",
    "    print(f\"   - RMSE: {float(train_rmse):.4f}\")\n",
    "    print(f\"   - MAE:  {train_mae:.4f}\")\n",
    "    print(f\"   - R¬≤:   {float(train_r2):.4f}\")\n",
    "    print(f\"\\n   Test Set:\")\n",
    "    print(f\"   - RMSE: {float(test_rmse):.4f}\")\n",
    "    print(f\"   - MAE:  {test_mae:.4f}\")\n",
    "    print(f\"   - R¬≤:   {float(test_r2):.4f}\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model': model,\n",
    "        'training_time': training_time,\n",
    "        'train_rmse': float(train_rmse),\n",
    "        'test_rmse': float(test_rmse),\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_r2': float(test_r2),\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred\n",
    "    }\n",
    "\n",
    "print(\"‚úì GPU evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6274ea",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Linear Regression (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb331ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression with cuML (GPU-accelerated)\n",
    "lr_model = cuLinearRegression(\n",
    "    fit_intercept=True,\n",
    "    algorithm='eig'  # 'eig' or 'svd'\n",
    ")\n",
    "\n",
    "lr_results = evaluate_model_gpu(\n",
    "    lr_model, X_train, X_test, y_train, y_test,\n",
    "    'Linear Regression (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_linear_regression_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "print(\"\\n‚úì Model saved: model_linear_regression_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f338ed",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Ridge Regression (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression with cuML (GPU-accelerated)\n",
    "ridge_model = cuRidge(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    solver='eig'  # 'eig' or 'svd'\n",
    ")\n",
    "\n",
    "ridge_results = evaluate_model_gpu(\n",
    "    ridge_model, X_train, X_test, y_train, y_test,\n",
    "    'Ridge Regression (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_ridge_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(ridge_model, f)\n",
    "print(\"\\n‚úì Model saved: model_ridge_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7020d8e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Lasso Regression (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression with cuML (GPU-accelerated)\n",
    "lasso_model = cuLasso(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "lasso_results = evaluate_model_gpu(\n",
    "    lasso_model, X_train, X_test, y_train, y_test,\n",
    "    'Lasso Regression (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_lasso_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(lasso_model, f)\n",
    "print(\"\\n‚úì Model saved: model_lasso_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92023de1",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ ElasticNet Regression (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet with cuML (GPU-accelerated)\n",
    "elasticnet_model = cuElasticNet(\n",
    "    alpha=1.0,\n",
    "    l1_ratio=0.5,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "elasticnet_results = evaluate_model_gpu(\n",
    "    elasticnet_model, X_train, X_test, y_train, y_test,\n",
    "    'ElasticNet (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_elasticnet_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(elasticnet_model, f)\n",
    "print(\"\\n‚úì Model saved: model_elasticnet_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9f6fc",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Decision Tree Regressor (CPU - sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor (CPU - no GPU version in cuML)\n",
    "print(\"\\n‚ö†Ô∏è  Decision Tree: Using sklearn (CPU) - no GPU implementation available\")\n",
    "\n",
    "# Convert cuDF to pandas for sklearn\n",
    "X_train_cpu = X_train.to_pandas() if hasattr(X_train, 'to_pandas') else X_train\n",
    "X_test_cpu = X_test.to_pandas() if hasattr(X_test, 'to_pandas') else X_test\n",
    "y_train_cpu = y_train.to_pandas() if hasattr(y_train, 'to_pandas') else y_train\n",
    "y_test_cpu = y_test.to_pandas() if hasattr(y_test, 'to_pandas') else y_test\n",
    "\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_results = evaluate_model(\n",
    "    dt_model, X_train_cpu, X_test_cpu, y_train_cpu, y_test_cpu,\n",
    "    'Decision Tree Regressor (sklearn CPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_decision_tree_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "print(\"\\n‚úì Model saved: model_decision_tree_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1461096",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Random Forest Regressor (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df67154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with cuML (GPU-accelerated)\n",
    "rf_model = cuRandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=16,\n",
    "    max_features='sqrt',\n",
    "    n_bins=128,\n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    "    n_streams=4  # GPU-specific: number of parallel streams\n",
    ")\n",
    "\n",
    "rf_results = evaluate_model_gpu(\n",
    "    rf_model, X_train, X_test, y_train, y_test,\n",
    "    'Random Forest (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_random_forest_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(\"\\n‚úì Model saved: model_random_forest_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d29b0",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Gradient Boosting Regressor (CPU - sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90950aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor (CPU - no GPU version in cuML)\n",
    "print(\"\\n‚ö†Ô∏è  Gradient Boosting: Using sklearn (CPU) - no GPU implementation available\")\n",
    "\n",
    "# Convert cuDF to pandas for sklearn\n",
    "X_train_cpu = X_train.to_pandas() if hasattr(X_train, 'to_pandas') else X_train\n",
    "X_test_cpu = X_test.to_pandas() if hasattr(X_test, 'to_pandas') else X_test\n",
    "y_train_cpu = y_train.to_pandas() if hasattr(y_train, 'to_pandas') else y_train\n",
    "y_test_cpu = y_test.to_pandas() if hasattr(y_test, 'to_pandas') else y_test\n",
    "\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_results = evaluate_model(\n",
    "    gb_model, X_train_cpu, X_test_cpu, y_train_cpu, y_test_cpu,\n",
    "    'Gradient Boosting Regressor (sklearn CPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_gradient_boosting_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(gb_model, f)\n",
    "print(\"\\n‚úì Model saved: model_gradient_boosting_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4497c",
   "metadata": {},
   "source": [
    "## üîü K-Nearest Neighbors Regressor (cuML GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with cuML (GPU-accelerated)\n",
    "knn_model = cuKNeighborsRegressor(\n",
    "    n_neighbors=5,\n",
    "    algorithm='brute',  # 'brute' uses GPU efficiently\n",
    "    metric='euclidean'\n",
    ")\n",
    "\n",
    "knn_results = evaluate_model_gpu(\n",
    "    knn_model, X_train, X_test, y_train, y_test,\n",
    "    'K-Nearest Neighbors (cuML GPU)'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_knn_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "print(\"\\n‚úì Model saved: model_knn_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536d3ce",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ XGBoost with GPU Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73298a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgboost_available:\n",
    "    # XGBoost with GPU acceleration\n",
    "    # Convert cuDF to DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(\n",
    "        X_train.to_pandas() if hasattr(X_train, 'to_pandas') else X_train,\n",
    "        label=y_train.to_pandas() if hasattr(y_train, 'to_pandas') else y_train\n",
    "    )\n",
    "    dtest = xgb.DMatrix(\n",
    "        X_test.to_pandas() if hasattr(X_test, 'to_pandas') else X_test,\n",
    "        label=y_test.to_pandas() if hasattr(y_test, 'to_pandas') else y_test\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: XGBoost (GPU Accelerated)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    params = {\n",
    "        'tree_method': 'gpu_hist',  # GPU acceleration!\n",
    "        'predictor': 'gpu_predictor',\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "        verbose_eval=20\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred_xgb = xgb_model.predict(dtrain)\n",
    "    y_test_pred_xgb = xgb_model.predict(dtest)\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train.to_pandas(), y_train_pred_xgb))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test.to_pandas(), y_test_pred_xgb))\n",
    "    train_mae = mean_absolute_error(y_train.to_pandas(), y_train_pred_xgb)\n",
    "    test_mae = mean_absolute_error(y_test.to_pandas(), y_test_pred_xgb)\n",
    "    train_r2 = r2_score(y_train.to_pandas(), y_train_pred_xgb)\n",
    "    test_r2 = r2_score(y_test.to_pandas(), y_test_pred_xgb)\n",
    "    \n",
    "    print(f\"\\nüìä Training Results:\")\n",
    "    print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"\\n   Test Set:\")\n",
    "    print(f\"   - RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"   - MAE:  {test_mae:.4f}\")\n",
    "    print(f\"   - R¬≤:   {test_r2:.4f}\")\n",
    "    \n",
    "    xgb_results = {\n",
    "        'model_name': 'XGBoost (GPU)',\n",
    "        'model': xgb_model,\n",
    "        'training_time': training_time,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'y_train_pred': y_train_pred_xgb,\n",
    "        'y_test_pred': y_test_pred_xgb\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    xgb_model.save_model('model_xgboost_rapids.json')\n",
    "    print(\"\\n‚úì Model saved: model_xgboost_rapids.json\")\n",
    "else:\n",
    "    xgb_results = None\n",
    "    print(\"‚ö† XGBoost not available - skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b4de5",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Support Vector Regressor (SVR) - CPU (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor (CPU - no GPU version in cuML)\n",
    "print(\"\\n‚ö†Ô∏è  SVR: Using sklearn (CPU) - no GPU implementation available\")\n",
    "print(\"‚ö†Ô∏è  Note: Training SVR on a subset (50,000 samples) due to computational cost...\")\n",
    "\n",
    "# Convert cuDF to pandas for sklearn\n",
    "X_train_cpu = X_train.to_pandas() if hasattr(X_train, 'to_pandas') else X_train\n",
    "X_test_cpu = X_test.to_pandas() if hasattr(X_test, 'to_pandas') else X_test\n",
    "y_train_cpu = y_train.to_pandas() if hasattr(y_train, 'to_pandas') else y_train\n",
    "y_test_cpu = y_test.to_pandas() if hasattr(y_test, 'to_pandas') else y_test\n",
    "\n",
    "# Use subset for SVR\n",
    "subset_size = min(50000, len(X_train_cpu))\n",
    "X_train_subset = X_train_cpu.iloc[:subset_size]\n",
    "y_train_subset = y_train_cpu.iloc[:subset_size]\n",
    "\n",
    "svr_model = SVR(\n",
    "    kernel='rbf',\n",
    "    C=10,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "svr_results = evaluate_model(\n",
    "    svr_model, X_train_subset, X_test_cpu, y_train_subset, y_test_cpu,\n",
    "    'Support Vector Regressor (SVR) - sklearn CPU'\n",
    ")\n",
    "\n",
    "# Save model\n",
    "with open('model_svr_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(svr_model, f)\n",
    "print(\"\\n‚úì Model saved: model_svr_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c83ca1",
   "metadata": {},
   "source": [
    "## üìä Compare All Models (GPU Training Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = [\n",
    "    lr_results,\n",
    "    ridge_results,\n",
    "    lasso_results,\n",
    "    elasticnet_results,\n",
    "    dt_results,\n",
    "    rf_results,\n",
    "    gb_results,\n",
    "    svr_results,\n",
    "    knn_results\n",
    "]\n",
    "\n",
    "if xgboost_available and xgb_results:\n",
    "    all_results.insert(7, xgb_results)  # Insert XGBoost after GB, before SVR\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': r['model_name'],\n",
    "        'Training Time (s)': r['training_time'],\n",
    "        'Test RMSE': r['test_rmse'],\n",
    "        'Test MAE': r['test_mae'],\n",
    "        'Test R¬≤': r['test_r2']\n",
    "    }\n",
    "    for r in all_results\n",
    "])\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Test RMSE', ascending=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON - GPU TRAINING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('model_results_rapids.csv', index=False)\n",
    "print(\"\\n‚úì Results saved: model_results_rapids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6527d1",
   "metadata": {},
   "source": [
    "## üìà Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Test RMSE Comparison\n",
    "axes[0, 0].barh(comparison_df['Model'], comparison_df['Test RMSE'], color='coral', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('RMSE (Lower is Better)', fontweight='bold')\n",
    "axes[0, 0].set_title('Test RMSE - GPU Trained Models', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Test MAE Comparison\n",
    "axes[0, 1].barh(comparison_df['Model'], comparison_df['Test MAE'], color='skyblue', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('MAE (Lower is Better)', fontweight='bold')\n",
    "axes[0, 1].set_title('Test MAE - GPU Trained Models', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Test R¬≤ Comparison\n",
    "axes[1, 0].barh(comparison_df['Model'], comparison_df['Test R¬≤'], color='lightgreen', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('R¬≤ Score (Higher is Better)', fontweight='bold')\n",
    "axes[1, 0].set_title('Test R¬≤ - GPU Trained Models', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Training Time Comparison\n",
    "axes[1, 1].barh(comparison_df['Model'], comparison_df['Training Time (s)'], color='gold', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Training Time (seconds)', fontweight='bold')\n",
    "axes[1, 1].set_title('GPU Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_rapids.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved: model_comparison_rapids.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa1a24",
   "metadata": {},
   "source": [
    "## üíæ Save All Results for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results for evaluation notebook\n",
    "with open('all_model_results_rapids.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(\"‚úì All model results saved: all_model_results_rapids.pkl\")\n",
    "print(\"\\nüìÅ Generated files:\")\n",
    "print(\"   Models:\")\n",
    "for result in all_results:\n",
    "    model_name = result['model_name'].lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    if 'xgboost' in model_name:\n",
    "        print(f\"   ‚Ä¢ model_{model_name.split()[0]}_rapids.json\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ model_{model_name.split()[0]}_rapids.pkl\")\n",
    "print(\"\\n   Results:\")\n",
    "print(\"   ‚Ä¢ all_model_results_rapids.pkl\")\n",
    "print(\"   ‚Ä¢ model_results_rapids.csv\")\n",
    "print(\"   ‚Ä¢ model_comparison_rapids.png\")\n",
    "print(\"   ‚Ä¢ test_indices_rapids.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68886e",
   "metadata": {},
   "source": [
    "## üéØ GPU Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef559e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GPU-ACCELERATED MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ TRAINED {len(all_results)} MODELS ON GPU:\")\n",
    "for i, result in enumerate(all_results, 1):\n",
    "    print(f\"   {i}. {result['model_name']}\")\n",
    "    print(f\"      - Test RMSE: {result['test_rmse']:.4f}\")\n",
    "    print(f\"      - Test R¬≤: {result['test_r2']:.4f}\")\n",
    "    print(f\"      - Training Time: {result['training_time']:.2f}s\")\n",
    "\n",
    "best_model = min(all_results, key=lambda x: x['test_rmse'])\n",
    "print(f\"\\nüèÜ BEST MODEL (Lowest Test RMSE):\")\n",
    "print(f\"   {best_model['model_name']}\")\n",
    "print(f\"   - Test RMSE: {best_model['test_rmse']:.4f}\")\n",
    "print(f\"   - Test MAE: {best_model['test_mae']:.4f}\")\n",
    "print(f\"   - Test R¬≤: {best_model['test_r2']:.4f}\")\n",
    "print(f\"   - Training Time: {best_model['training_time']:.2f}s\")\n",
    "\n",
    "print(\"\\nüöÄ GPU ACCELERATION BENEFITS:\")\n",
    "print(\"   ‚Ä¢ Linear models: 10-50x faster than scikit-learn\")\n",
    "print(\"   ‚Ä¢ Random Forest: 10-25x faster training\")\n",
    "print(\"   ‚Ä¢ KNN: Efficient GPU distance calculations\")\n",
    "print(\"   ‚Ä¢ XGBoost: Native GPU histogram algorithm\")\n",
    "\n",
    "print(\"\\nüí° NEXT STEPS:\")\n",
    "print(\"   1. Use Model_Evaluation_RAPIDS.ipynb for detailed analysis\")\n",
    "print(\"   2. Compare GPU vs CPU training times\")\n",
    "print(\"   3. Perform GPU-accelerated hyperparameter tuning\")\n",
    "print(\"   4. Deploy models with GPU inference\")\n",
    "\n",
    "print(\"\\nüéµ APPLICATION:\")\n",
    "print(\"   GPU-powered prediction of song release years - FAST!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Report GPU memory usage\n",
    "mempool = cp.get_default_memory_pool()\n",
    "print(f\"\\nüìä GPU Memory Usage:\")\n",
    "print(f\"   Used: {mempool.used_bytes() / 1024**2:.2f} MB\")\n",
    "print(f\"   Total: {mempool.total_bytes() / 1024**2:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
